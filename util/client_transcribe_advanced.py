# new/util/client_transcribe_advanced.py
import os
import subprocess
import srt
import chardet
import asyncio
import uuid
from pathlib import Path
from moviepy.editor import AudioFileClip
from typing import List, Tuple, Optional

from config import ClientConfig as Config
from util.client_transcribe import transcribe_check, transcribe_send, transcribe_recv
from util.client_cosmic import console, Cosmic

# Helper to get media duration using ffprobe
def get_media_duration_ffprobe(file_path: Path) -> Optional[float]:
    try:
        command = f'ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 "{file_path}"'
        duration_str = subprocess.check_output(command, shell=True, stderr=subprocess.STDOUT).decode().strip()
        return float(duration_str)
    except Exception as e:
        console.print(f"[bold red]Error getting media duration for {file_path}: {e}[/bold red]")
        return None

# Helper to extract audio using the configured FFmpeg command
def extract_audio_with_ffmpeg(input_media_path: Path, output_audio_path: Path) -> bool:
    cmd = []
    for part in Config.FFMPEG_AUDIO_EXTRACTION_CMD_TEMPLATE:
        if part == "{input_file}":
            cmd.append(str(input_media_path))
        elif part == "{output_file}":
            cmd.append(str(output_audio_path))
        else:
            cmd.append(part)

    console.print(f"Extracting audio to: {output_audio_path}")
    try:
        process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        stdout, stderr = process.communicate()
        if process.returncode != 0:
            console.print(f"[bold red]FFmpeg audio extraction failed for {input_media_path}[/bold red]")
            console.print(f"[bold red]FFmpeg stderr:[/bold red]\n{stderr.decode(errors='ignore')}")
            return False
        return True
    except Exception as e:
        console.print(f"[bold red]Exception during FFmpeg audio extraction for {input_media_path}: {e}[/bold red]")
        return False

# Helper to split audio using moviepy
def split_audio_moviepy(audio_path: Path, split_duration_seconds: int) -> Optional[List[Path]]:
    chunk_paths = []
    audio = None  # Initialize audio to None
    try:
        audio = AudioFileClip(str(audio_path))
        duration = audio.duration
        if duration <= split_duration_seconds:
            audio.close()
            return [audio_path] # No splitting needed

        num_splits = int(duration / split_duration_seconds) + 1
        base_name = audio_path.stem
        output_dir = audio_path.parent

        console.print(f"Splitting audio into {num_splits} chunks...")
        for i in range(num_splits):
            start_time = i * split_duration_seconds
            end_time = min((i + 1) * split_duration_seconds, duration)
            subclip = audio.subclip(start_time, end_time)
            
            chunk_filename = f"{base_name}{Config.SPLIT_AUDIO_SUFFIX_PREFIX}{i}{audio_path.suffix}"
            chunk_path = output_dir / chunk_filename
            subclip.write_audiofile(str(chunk_path), codec='pcm_s16le', verbose=False, logger=None)
            chunk_paths.append(chunk_path)
        
        audio.close()
        return chunk_paths
    except Exception as e:
        console.print(f"[bold red]Error splitting audio {audio_path}: {e}[/bold red]")
        # Attempt to close audio clip if it was opened
        if 'audio' in locals() and audio is not None:
            audio.close()
        return None

# Helper to transcribe a single audio chunk using existing logic
async def transcribe_audio_chunk(chunk_path: Path, original_task_id_base: str, chunk_index: int) -> Optional[Tuple[Path, Path]]:
    chunk_task_id = f"{original_task_id_base}_{chunk_index}" # For logging, actual task_id is generated by transcribe_send
    console.print(f"  Transcribing chunk {chunk_index} ({chunk_path.name})")

    try:
        await transcribe_check(chunk_path) # Check connection and file existence for this specific chunk
        if not Cosmic.websocket:
             console.print(f"[bold red]Cannot connect to server for chunk {chunk_path.name}. Aborting this chunk.[/bold red]")
             return None

        await transcribe_send(chunk_path)
        await transcribe_recv(chunk_path) # This function writes the .txt, .json, .merge.txt, .srt files

        # transcribe_recv writes files with the same base name as chunk_path
        txt_file = chunk_path.with_suffix(".txt")
        srt_file = chunk_path.with_suffix(".srt")
        
        if txt_file.exists() and srt_file.exists():
            return txt_file, srt_file
        else:
            console.print(f"[bold red]Transcription of chunk {chunk_path.name} did not produce expected output files.[/bold red]")
            return None
    except Exception as e:
        console.print(f"[bold red]Error transcribing chunk {chunk_path.name}: {e}[/bold red]")
        return None
    finally:
        if Cosmic.websocket:
            await Cosmic.websocket.close()
            console.print(f"  Closed WebSocket connection for chunk {chunk_path.name}")

# Helper to merge TXT files (adapted from media2srt.py)
def merge_txt_files(original_file_path: Path, chunk_txt_paths: List[Path]) -> Optional[Path]:
    if not chunk_txt_paths:
        return None
    
    merged_content = ""
    for txt_path in sorted(chunk_txt_paths): # Sort to ensure order
        try:
            with open(txt_path, 'rb') as f:
                raw_data = f.read()
                detected_encoding = chardet.detect(raw_data)['encoding']
                content = raw_data.decode(detected_encoding if detected_encoding else 'utf-8')
                merged_content += content + "\n"
        except Exception as e:
            console.print(f"[bold red]Error reading chunk TXT {txt_path}: {e}[/bold red]")
            return None
    
    final_txt_path = original_file_path.with_suffix(".txt")
    try:
        with open(final_txt_path, 'w', encoding='utf-8') as f:
            f.write(merged_content)
        console.print(f"Merged TXT file created: {final_txt_path}")
        return final_txt_path
    except Exception as e:
        console.print(f"[bold red]Error writing merged TXT {final_txt_path}: {e}[/bold red]")
        return None

# Helper to correct and merge SRT files (adapted from media2srt.py)
def correct_and_merge_srt_files(original_file_path: Path, chunk_srt_paths: List[Path]) -> Optional[Path]:
    if not chunk_srt_paths:
        return None

    merged_subtitles = []
    current_time_offset = 0.0

    for srt_path in sorted(chunk_srt_paths): # Sort to ensure order
        try:
            with open(srt_path, 'rb') as f:
                raw_data = f.read()
                detected_encoding = chardet.detect(raw_data)['encoding']
                content = raw_data.decode(detected_encoding if detected_encoding else 'utf-8')
                subtitles = list(srt.parse(content))

            if not subtitles:
                continue

            # Calculate duration of this chunk to update the offset for the next one
            # Use the end time of the last subtitle in the chunk
            last_subtitle_end_time = subtitles[-1].end.total_seconds()
            
            for subtitle in subtitles:
                # Apply time offset
                subtitle.start = srt.timedelta(seconds=subtitle.start.total_seconds() + current_time_offset)
                subtitle.end = srt.timedelta(seconds=subtitle.end.total_seconds() + current_time_offset)
                subtitle.index = len(merged_subtitles) + 1 # Re-index
                merged_subtitles.append(subtitle)
            
            current_time_offset += last_subtitle_end_time

        except Exception as e:
            console.print(f"[bold red]Error processing/correcting chunk SRT {srt_path}: {e}[/bold red]")
            return None
    
    final_srt_path = original_file_path.with_suffix(".srt")
    try:
        with open(final_srt_path, 'w', encoding='utf-8') as f:
            f.write(srt.compose(merged_subtitles))
        console.print(f"Merged and corrected SRT file created: {final_srt_path}")
        return final_srt_path
    except Exception as e:
        console.print(f"[bold red]Error writing merged SRT {final_srt_path}: {e}[/bold red]")
        return None

# Helper to clean up intermediate files based on their stems
def cleanup_intermediate_files_by_stems(stems_to_remove: List[str]):
    for stem_str in stems_to_remove:
        # Define the suffixes of files to be removed
        suffixes_to_remove = [".wav", ".txt", ".srt", ".json", ".merge.txt"]
        for suffix in suffixes_to_remove:
            file_to_remove = Path(str(stem_str) + suffix)
            try:
                if file_to_remove.exists():
                    os.remove(file_to_remove)
                    console.print(f"Cleaned up: {file_to_remove}")
            except OSError as e:
                console.print(f"[yellow]Error deleting {file_to_remove}: {e}[/yellow]")

# Main function to process a media file
async def process_media_file(file_path: Path):
    console.print(f"\n[cyan][Process Media File] Starting for: {file_path}[/cyan]")
    
    final_srt_path = file_path.with_suffix(".srt")
    final_txt_path = file_path.with_suffix(".txt")

    if final_srt_path.exists() and final_txt_path.exists():
        console.print(f"[yellow]Skipping {file_path} as .srt and .txt already exist.[/yellow]")
        return

    base_task_id = str(uuid.uuid1())
    temp_audio_path_stem = file_path.with_name(file_path.name + Config.TEMP_AUDIO_SUFFIX).stem
    stems_to_cleanup = [temp_audio_path_stem] # Store stems for cleanup

    try:
        # 1. Extract Audio
        # The actual temp audio path is needed for extraction
        actual_temp_audio_path = Path(str(temp_audio_path_stem) + ".wav") 
        if not extract_audio_with_ffmpeg(file_path, actual_temp_audio_path):
            console.print(f"[bold red]Audio extraction failed for {file_path}.[/bold red]")
            return

        duration = get_media_duration_ffprobe(actual_temp_audio_path)
        if duration is None:
            console.print(f"[bold red]Could not get duration for {actual_temp_audio_path}.[/bold red]")
            return
        
        console.print(f"Original audio duration: {duration:.2f}s")

        # 2. Split if necessary
        audio_chunks_to_transcribe: List[Path] = []
        if duration > Config.SPLIT_DURATION_SECONDS:
            console.print(f"Duration exceeds split threshold ({Config.SPLIT_DURATION_SECONDS}s). Splitting audio.")
            split_chunks = split_audio_moviepy(actual_temp_audio_path, Config.SPLIT_DURATION_SECONDS)
            if split_chunks:
                audio_chunks_to_transcribe.extend(split_chunks)
                # Add stems of split chunks for cleanup
                stems_to_cleanup.extend([p.stem for p in split_chunks])
            else:
                console.print(f"[bold red]Audio splitting failed for {actual_temp_audio_path}.[/bold red]")
                # Cleanup the main temp audio file if splitting failed
                cleanup_intermediate_files_by_stems(stems_to_cleanup) # Use new cleanup function
                return
        else:
            console.print("Duration within threshold. Processing as a single chunk.")
            audio_chunks_to_transcribe.append(actual_temp_audio_path)
            # The stem for cleanup is already temp_audio_path_stem
        
        # 3. Transcribe Chunks
        transcribed_chunk_txts: List[Path] = []
        transcribed_chunk_srts: List[Path] = []
        for i, chunk_path in enumerate(audio_chunks_to_transcribe):
            result = await transcribe_audio_chunk(chunk_path, base_task_id, i)
            if result:
                txt_file, srt_file = result
                transcribed_chunk_txts.append(txt_file)
                transcribed_chunk_srts.append(srt_file)
                # Stems for these are already in stems_to_cleanup from split_chunks or temp_audio_path_stem
            else:
                console.print(f"[bold red]Failed to transcribe chunk {chunk_path.name}. Aborting merge for {file_path.name}.[/bold red]")
                # Decide if we should cleanup and exit, or try to merge what we have.
                # For now, let's cleanup and exit.
                cleanup_intermediate_files_by_stems(stems_to_cleanup) # Use new cleanup function
                return
        
        # 4. Merge Results
        if len(audio_chunks_to_transcribe) > 1: # Only merge if it was split
            if transcribed_chunk_txts:
                merge_txt_files(file_path, transcribed_chunk_txts)
            if transcribed_chunk_srts:
                correct_and_merge_srt_files(file_path, transcribed_chunk_srts)
        else: # Single chunk, just rename output files to final names
            if transcribed_chunk_txts:
                try:
                    os.rename(transcribed_chunk_txts[0], final_txt_path)
                    console.print(f"Renamed {transcribed_chunk_txts[0].name} to {final_txt_path.name}")
                except OSError as e:
                    console.print(f"[bold red]Error renaming TXT file: {e}[/bold red]")
            if transcribed_chunk_srts:
                try:
                    os.rename(transcribed_chunk_srts[0], final_srt_path)
                    console.print(f"Renamed {transcribed_chunk_srts[0].name} to {final_srt_path.name}")
                except OSError as e:
                    console.print(f"[bold red]Error renaming SRT file: {e}[/bold red]")
        
        console.print(f"[green][Process Media File] Successfully completed for: {file_path}[/green]")

    finally:
        # 5. Cleanup
        cleanup_intermediate_files_by_stems(stems_to_cleanup)
